{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸŒ¸ Flower Species Classification Using CNN (Oxford Flowers Dataset)"
      ],
      "metadata": {
        "id": "F7q5SzM770W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“¥Step 1: Unzip the file"
      ],
      "metadata": {
        "id": "QIh7xfqQ8QXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the uploaded zip file\n",
        "zip_file_path = '/content/flower_dataset.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/flower_dataset')\n",
        "\n",
        "# Verify the files were extracted\n",
        "extracted_files = os.listdir('/content/flower_dataset')\n",
        "print(extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVtfUiHd8DWh",
        "outputId": "8460838d-65b2-43c9-ce02-383f4810d878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample_submission.csv', 'cat_to_name.json', 'dataset', 'README.md']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/flower_dataset/dataset'\n",
        "classes = os.listdir(dataset_path)\n",
        "print(classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjI_wE65Gwuw",
        "outputId": "372d87b0-3a31-4f53-a069-19ac41074977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['valid', 'train', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Import Required Libraries\n",
        "First, let's import the necessary libraries. We will be using TensorFlow and Keras for constructing the model, as well as libraries like NumPy and Matplotlib for data handling and visualization."
      ],
      "metadata": {
        "id": "OhbOrPXlBL1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ],
      "metadata": {
        "id": "aFLl0eKTBK2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§¹Step 3: Setup Paths\n",
        "Define the paths where your dataset and other required files are located.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bTKU5dRTBjp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/flower_dataset/dataset'  # Path where your dataset is located\n",
        "train_dir = os.path.join(base_path, 'train')\n",
        "valid_dir = os.path.join(base_path, 'valid')\n",
        "test_dir = os.path.join(base_path, 'test')\n",
        "\n",
        "json_path = '/content/flower_dataset/cat_to_name.json'  # Path to the cat_to_name.json file\n"
      ],
      "metadata": {
        "id": "3hxV554ABrf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Load the cat_to_name Mapping\n",
        "In this step, we load the cat_to_name.json file which maps the class IDs to the actual flower names."
      ],
      "metadata": {
        "id": "tFfIv46RB0cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(json_path, 'r') as f:\n",
        "    cat_to_name = json.load(f)\n",
        "\n",
        "# Optional: convert keys to int if needed\n",
        "cat_to_name = {int(k): v for k, v in cat_to_name.items()}\n",
        "print(cat_to_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQjQDv90B5ty",
        "outputId": "8340b3ee-3015-4a1a-9002-1c9a87add70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{21: 'fire lily', 3: 'canterbury bells', 45: 'bolero deep blue', 1: 'pink primrose', 34: 'mexican aster', 27: 'prince of wales feathers', 7: 'moon orchid', 16: 'globe-flower', 25: 'grape hyacinth', 26: 'corn poppy', 79: 'toad lily', 39: 'siam tulip', 24: 'red ginger', 67: 'spring crocus', 35: 'alpine sea holly', 32: 'garden phlox', 10: 'globe thistle', 6: 'tiger lily', 93: 'ball moss', 33: 'love in the mist', 9: 'monkshood', 102: 'blackberry lily', 14: 'spear thistle', 19: 'balloon flower', 100: 'blanket flower', 13: 'king protea', 49: 'oxeye daisy', 15: 'yellow iris', 61: 'cautleya spicata', 31: 'carnation', 64: 'silverbush', 68: 'bearded iris', 63: 'black-eyed susan', 69: 'windflower', 62: 'japanese anemone', 20: 'giant white arum lily', 38: 'great masterwort', 4: 'sweet pea', 86: 'tree mallow', 101: 'trumpet creeper', 42: 'daffodil', 22: 'pincushion flower', 2: 'hard-leaved pocket orchid', 54: 'sunflower', 66: 'osteospermum', 70: 'tree poppy', 85: 'desert-rose', 99: 'bromelia', 87: 'magnolia', 5: 'english marigold', 92: 'bee balm', 28: 'stemless gentian', 97: 'mallow', 57: 'gaura', 40: 'lenten rose', 47: 'marigold', 59: 'orange dahlia', 48: 'buttercup', 55: 'pelargonium', 36: 'ruby-lipped cattleya', 91: 'hippeastrum', 29: 'artichoke', 71: 'gazania', 90: 'canna lily', 18: 'peruvian lily', 98: 'mexican petunia', 8: 'bird of paradise', 30: 'sweet william', 17: 'purple coneflower', 52: 'wild pansy', 84: 'columbine', 12: \"colt's foot\", 11: 'snapdragon', 96: 'camellia', 23: 'fritillary', 50: 'common dandelion', 44: 'poinsettia', 53: 'primula', 72: 'azalea', 65: 'californian poppy', 80: 'anthurium', 76: 'morning glory', 37: 'cape flower', 56: 'bishop of llandaff', 60: 'pink-yellow dahlia', 82: 'clematis', 58: 'geranium', 75: 'thorn apple', 41: 'barbeton daisy', 95: 'bougainvillea', 43: 'sword lily', 83: 'hibiscus', 78: 'lotus lotus', 88: 'cyclamen', 94: 'foxglove', 81: 'frangipani', 74: 'rose', 89: 'watercress', 73: 'water lily', 46: 'wallflower', 77: 'passion flower', 51: 'petunia'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“ŠStep 5: Data Preprocessing and Augmentation\n",
        "Data augmentation helps in improving generalization and reducing overfitting. We apply several augmentations like rotation, zoom, horizontal flip, etc., to the training data. We only rescale the validation and test data to normalize the pixel values.\n",
        "\n"
      ],
      "metadata": {
        "id": "yTtOPt49B9qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing and Augmentation\n",
        "img_size = (224, 224)  # Resize all images to 224x224 pixels\n",
        "batch_size = 32\n",
        "\n",
        "# Data Augmentation for Training Data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale image pixel values to [0, 1]\n",
        "    rotation_range=40,  # Random rotation from 0 to 40 degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shift\n",
        "    height_shift_range=0.2,  # Random vertical shift\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flip\n",
        "    fill_mode='nearest'  # Fill missing pixels after transformations\n",
        ")\n",
        "\n",
        "# Data Augmentation for Validation Data (only rescaling)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data Augmentation for Test Data (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create Data Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'  # Since this is a multi-class classification problem\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIOxOa0ECByn",
        "outputId": "7e706495-202e-4b47-98a0-c511e14d431a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6552 images belonging to 102 classes.\n",
            "Found 818 images belonging to 102 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§ Step 6: Build the CNN Model\n",
        "Now, we create a Convolutional Neural Network (CNN) for flower species classification. We include convolution layers for feature extraction, pooling layers for dimensionality reduction, and fully connected layers for classification. Additionally, we use different activation functions (ReLU, LeakyReLU, Softmax) and include dropout and L2 regularization to handle overfitting."
      ],
      "metadata": {
        "id": "mFzoQaVwChwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the CNN Model\n",
        "num_classes = train_generator.num_classes  # Number of classes in the dataset\n",
        "\n",
        "model = models.Sequential([\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation=LeakyReLU(alpha=0.1)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Flatten Layer\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Fully Connected Layer with Dropout and L2 Regularization\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "\n",
        "    # Output Layer with Softmax activation for multi-class classification\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Model summary to check the architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "i31du-eHCwCk",
        "outputId": "ff7318d3-15c1-47ef-d41a-b482da9b736d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚           \u001b[38;5;34m896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚    \u001b[38;5;34m44,302,848\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)            â”‚        \u001b[38;5;34m52,326\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">44,302,848</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,326</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,448,422\u001b[0m (169.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,448,422</span> (169.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,448,422\u001b[0m (169.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,448,422</span> (169.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Compile the Model\n",
        "Now, we compile the model using categorical cross-entropy loss (since this is a multi-class classification problem) and an optimizer (Adam in this case).\n",
        "\n"
      ],
      "metadata": {
        "id": "LHTnlUaoC2pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the Model\n",
        "optimizer = Adam(learning_rate=0.001)  # Adam optimizer\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',  # Multi-class cross-entropy loss\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']  # Track accuracy during training\n",
        ")\n"
      ],
      "metadata": {
        "id": "pf6wXDL2C7R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Define Callbacks\n",
        "Callbacks like ReduceLROnPlateau and EarlyStopping help with learning rate adjustment and stopping the training early if the model starts overfitting."
      ],
      "metadata": {
        "id": "ha4KK7YCDUZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "sbB2grdNDXpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Train the Model\n",
        "Now, we train the model on the training data and validate it on the validation set. We will also plot the training history to observe how the accuracy and loss evolve during the training."
      ],
      "metadata": {
        "id": "bMLg4Sx6Dbzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=35,  # Set a reasonable number of epochs\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=[early_stop, lr_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64-h5IXrDeHg",
        "outputId": "e1ad72a9-0482-4041-e08f-11e30d470da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 477ms/step - accuracy: 0.0671 - loss: 4.8646 - val_accuracy: 0.1687 - val_loss: 3.7406 - learning_rate: 0.0010\n",
            "Epoch 2/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 445ms/step - accuracy: 0.1866 - loss: 3.6943 - val_accuracy: 0.2311 - val_loss: 3.4661 - learning_rate: 0.0010\n",
            "Epoch 3/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 447ms/step - accuracy: 0.2347 - loss: 3.4928 - val_accuracy: 0.2689 - val_loss: 3.2850 - learning_rate: 0.0010\n",
            "Epoch 4/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 439ms/step - accuracy: 0.2927 - loss: 3.2875 - val_accuracy: 0.3203 - val_loss: 3.1730 - learning_rate: 0.0010\n",
            "Epoch 5/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 441ms/step - accuracy: 0.3388 - loss: 3.1416 - val_accuracy: 0.3900 - val_loss: 3.0726 - learning_rate: 0.0010\n",
            "Epoch 6/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.3420 - loss: 3.0908 - val_accuracy: 0.4046 - val_loss: 3.0071 - learning_rate: 0.0010\n",
            "Epoch 7/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.3702 - loss: 3.0118 - val_accuracy: 0.4279 - val_loss: 2.8581 - learning_rate: 0.0010\n",
            "Epoch 8/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 438ms/step - accuracy: 0.3941 - loss: 2.9640 - val_accuracy: 0.4511 - val_loss: 2.8174 - learning_rate: 0.0010\n",
            "Epoch 9/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.4149 - loss: 2.8816 - val_accuracy: 0.4450 - val_loss: 2.9616 - learning_rate: 0.0010\n",
            "Epoch 10/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.4446 - loss: 2.8501 - val_accuracy: 0.4645 - val_loss: 2.7768 - learning_rate: 0.0010\n",
            "Epoch 11/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 431ms/step - accuracy: 0.4581 - loss: 2.7639 - val_accuracy: 0.4389 - val_loss: 2.9379 - learning_rate: 0.0010\n",
            "Epoch 12/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.4407 - loss: 2.8040 - val_accuracy: 0.4768 - val_loss: 2.8146 - learning_rate: 0.0010\n",
            "Epoch 13/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.4865 - loss: 2.7059\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 431ms/step - accuracy: 0.4865 - loss: 2.7060 - val_accuracy: 0.5061 - val_loss: 2.8268 - learning_rate: 0.0010\n",
            "Epoch 14/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.5060 - loss: 2.6001 - val_accuracy: 0.5685 - val_loss: 2.4191 - learning_rate: 5.0000e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 432ms/step - accuracy: 0.5504 - loss: 2.3252 - val_accuracy: 0.5562 - val_loss: 2.5439 - learning_rate: 5.0000e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.5717 - loss: 2.2350 - val_accuracy: 0.5709 - val_loss: 2.3611 - learning_rate: 5.0000e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.5687 - loss: 2.2099 - val_accuracy: 0.5416 - val_loss: 2.4920 - learning_rate: 5.0000e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 432ms/step - accuracy: 0.5822 - loss: 2.1444 - val_accuracy: 0.5489 - val_loss: 2.4457 - learning_rate: 5.0000e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.5906 - loss: 2.1202 - val_accuracy: 0.5966 - val_loss: 2.2637 - learning_rate: 5.0000e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.6061 - loss: 2.0591 - val_accuracy: 0.5770 - val_loss: 2.3480 - learning_rate: 5.0000e-04\n",
            "Epoch 21/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.6043 - loss: 2.0297 - val_accuracy: 0.6222 - val_loss: 2.1278 - learning_rate: 5.0000e-04\n",
            "Epoch 22/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.5943 - loss: 2.0605 - val_accuracy: 0.5685 - val_loss: 2.4035 - learning_rate: 5.0000e-04\n",
            "Epoch 23/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.6150 - loss: 1.9981 - val_accuracy: 0.5905 - val_loss: 2.3265 - learning_rate: 5.0000e-04\n",
            "Epoch 24/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.6218 - loss: 1.9500\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.6217 - loss: 1.9503 - val_accuracy: 0.6015 - val_loss: 2.2441 - learning_rate: 5.0000e-04\n",
            "Epoch 25/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.6516 - loss: 1.8636 - val_accuracy: 0.6271 - val_loss: 2.1840 - learning_rate: 2.5000e-04\n",
            "Epoch 26/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 431ms/step - accuracy: 0.6654 - loss: 1.7749 - val_accuracy: 0.6222 - val_loss: 2.1395 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop, lr_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf9PJckOSORv",
        "outputId": "274673c0-f562-4a73-be4e-cb073c71b7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.6248 - loss: 1.9219 - val_accuracy: 0.6381 - val_loss: 2.0432 - learning_rate: 2.5000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 469ms/step - accuracy: 0.6472 - loss: 1.8276 - val_accuracy: 0.6112 - val_loss: 2.1416 - learning_rate: 2.5000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 444ms/step - accuracy: 0.6651 - loss: 1.7527 - val_accuracy: 0.6320 - val_loss: 2.0052 - learning_rate: 2.5000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 446ms/step - accuracy: 0.6622 - loss: 1.7187 - val_accuracy: 0.6394 - val_loss: 2.0015 - learning_rate: 2.5000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 437ms/step - accuracy: 0.6633 - loss: 1.7229 - val_accuracy: 0.6296 - val_loss: 2.0123 - learning_rate: 2.5000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.6799 - loss: 1.6464 - val_accuracy: 0.6222 - val_loss: 2.0135 - learning_rate: 2.5000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 439ms/step - accuracy: 0.6760 - loss: 1.6471 - val_accuracy: 0.6357 - val_loss: 1.9495 - learning_rate: 2.5000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 438ms/step - accuracy: 0.6905 - loss: 1.5957 - val_accuracy: 0.6394 - val_loss: 1.9665 - learning_rate: 2.5000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 441ms/step - accuracy: 0.6927 - loss: 1.5962 - val_accuracy: 0.6345 - val_loss: 1.9706 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.6856 - loss: 1.5636\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 435ms/step - accuracy: 0.6855 - loss: 1.5638 - val_accuracy: 0.6247 - val_loss: 2.0442 - learning_rate: 2.5000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 449ms/step - accuracy: 0.7034 - loss: 1.5460 - val_accuracy: 0.6369 - val_loss: 1.9510 - learning_rate: 1.2500e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.7149 - loss: 1.4540 - val_accuracy: 0.6504 - val_loss: 1.8930 - learning_rate: 1.2500e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.7234 - loss: 1.4370 - val_accuracy: 0.6479 - val_loss: 1.8999 - learning_rate: 1.2500e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 441ms/step - accuracy: 0.7146 - loss: 1.4222 - val_accuracy: 0.6528 - val_loss: 1.9192 - learning_rate: 1.2500e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - accuracy: 0.7284 - loss: 1.3897\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.7284 - loss: 1.3898 - val_accuracy: 0.6528 - val_loss: 1.9118 - learning_rate: 1.2500e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 444ms/step - accuracy: 0.7420 - loss: 1.3420 - val_accuracy: 0.6626 - val_loss: 1.8715 - learning_rate: 6.2500e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 438ms/step - accuracy: 0.7356 - loss: 1.3289 - val_accuracy: 0.6577 - val_loss: 1.8734 - learning_rate: 6.2500e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7404 - loss: 1.3106 - val_accuracy: 0.6601 - val_loss: 1.8603 - learning_rate: 6.2500e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7385 - loss: 1.3123 - val_accuracy: 0.6577 - val_loss: 1.8721 - learning_rate: 6.2500e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 456ms/step - accuracy: 0.7437 - loss: 1.2899 - val_accuracy: 0.6663 - val_loss: 1.8602 - learning_rate: 6.2500e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stop, lr_reduction]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqXSSrH0ZVBK",
        "outputId": "cfdcbe15-1e2d-4b06-9b79-7dba525966b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.7503 - loss: 1.2822 - val_accuracy: 0.6687 - val_loss: 1.8317 - learning_rate: 6.2500e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 446ms/step - accuracy: 0.7474 - loss: 1.2905 - val_accuracy: 0.6687 - val_loss: 1.8325 - learning_rate: 6.2500e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.7507 - loss: 1.2800 - val_accuracy: 0.6638 - val_loss: 1.8938 - learning_rate: 6.2500e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.7498 - loss: 1.2811\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 429ms/step - accuracy: 0.7498 - loss: 1.2810 - val_accuracy: 0.6601 - val_loss: 1.8627 - learning_rate: 6.2500e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7549 - loss: 1.2283 - val_accuracy: 0.6711 - val_loss: 1.8298 - learning_rate: 3.1250e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 431ms/step - accuracy: 0.7687 - loss: 1.2003 - val_accuracy: 0.6711 - val_loss: 1.7817 - learning_rate: 3.1250e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7695 - loss: 1.2158 - val_accuracy: 0.6773 - val_loss: 1.7709 - learning_rate: 3.1250e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.7624 - loss: 1.1779 - val_accuracy: 0.6748 - val_loss: 1.7905 - learning_rate: 3.1250e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 437ms/step - accuracy: 0.7760 - loss: 1.1580 - val_accuracy: 0.6540 - val_loss: 1.8522 - learning_rate: 3.1250e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.7683 - loss: 1.1875\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.7683 - loss: 1.1876 - val_accuracy: 0.6614 - val_loss: 1.8230 - learning_rate: 3.1250e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7833 - loss: 1.1533 - val_accuracy: 0.6675 - val_loss: 1.8316 - learning_rate: 1.5625e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.7705 - loss: 1.1691 - val_accuracy: 0.6687 - val_loss: 1.8156 - learning_rate: 1.5625e-05\n"
          ]
        }
      ]
    }
  ]
}